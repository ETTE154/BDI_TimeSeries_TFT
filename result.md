# 결과 분석 방법

### plot_prediction 함수는 실제 값과 예측 그리고 어텐션을 시각화합니다.

#### 매개변수:
  - **x** (Dict[str, torch.Tensor]): 네트워크 입력
  - **out** (Dict[str, torch.Tensor]): 네트워크 출력
  - **idx** (int): 샘플 인덱스
  - **plot_attention** (bool): 보조 축에 어텐션을 그릴지 여부, 기본값은 True입니다.
  - **add_loss_to_title** (bool): 제목에 손실을 추가할지 여부, 기본값은 False입니다.
  - **show_future_observed** (bool): 미래 실제 값을 표시할지 여부, 기본값은 True입니다.
  - **ax**: 그림을 그릴 matplotlib 축
  - **반환 값**:
    - plt.Figure: matplotlib 그림 함수는 먼저 일반적인 예측을 그립니다. 그런 다음 plot_attention이 True이면, 보조 축에 어텐션을 추가합니다. 
      이를 위해 interpret_output 함수를 사용하여 out의 해석을 얻고, 그 결과를 사용하여 어텐션을 그립니다. 마지막으로 tight_layout() 함수를 호출하여 그림의 레이아웃을 조정합니다.

#### Attention
  - 어텐션(Attention)은 딥러닝 모델, 특히 시퀀스 처리 작업에서 중요한 정보에 초점을 맞추도록 도움을 주는 메커니즘입니다.
    어텐션은 모델이 입력 시퀀스의 각 부분에 가중치를 할당하여 중요한 부분에 높은 가중치를 부여하고 상대적으로 덜 중요한 부분에 낮은 가중치를 부여합니다. 
    이를 통해 모델이 더욱 효과적으로 학습하고 예측을 수행할 수 있습니다.

#### plot_prediction 함수에서 어텐션을 그리는 과정은 다음과 같습니다:

  1. **interpret_output** 함수를 사용하여 네트워크 출력인 out의 해석을 얻습니다. 이 함수는 출력에 대한 어텐션 가중치를 계산합니다.
  2. 어텐션 가중치를 그래프로 그리기 위해, 먼저 기본 축(ax)에 대한 보조 축(ax2)을 생성합니다. 이렇게 하면 어텐션 그래프가 예측 그래프와 겹치지 않고 독립적으로 그려집니다.
  3. 보조 축에 **"Attention"** 레이블을 붙입니다.
  4. 인코더 길이를 사용하여 x축 범위를 설정하고, 어텐션 가중치를 y축 값으로 사용하여 그래프를 그립니다. 그래프의 투명도는 0.2로 설정하고, 선 색상은 검정색으로 지정합니다.
  5. **tight_layout**() 함수를 호출하여 그림의 레이아웃을 조정합니다.

  결과적으로, 이 함수는 예측 그래프와 함께 어텐션 가중치를 시각화하여, 어떤 입력 부분이 모델에 의해 더 중요하게 여겨지는지 이해하는 데 도움이 됩니다.
